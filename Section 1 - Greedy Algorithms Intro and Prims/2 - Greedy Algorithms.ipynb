{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Algorithm Design: no \"silver bullet\" that applies to every possible problem. \n",
    "\n",
    "Some Paradigms:\n",
    " - Divide and Conquer (e.g. MergeSort) \n",
    " - Randomized Algorithms (e.g. QuickSort, Hash Functions)\n",
    " - Greedy Algorithm (Iteratively make myopic decisions; e.g. Dijkstra's)\n",
    " - Dynamic Programming (solves for ex sequence alignment, distributed shortest path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Greedy Algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definition: Iteratively make \"myopic\" decisions, hope things works out at the end\n",
    " - Myopic - decisions that are made are good ideas at the time the decision is made\n",
    " \n",
    "EX: Dijkstra's shortest path\n",
    " - Processed each destination once (greedy), irrevocably. Greedy bc of such. Gets one shot to compute shortest path to a given destination, makes that decision myopicaly. \n",
    " \n",
    "Contrast with DnC:\n",
    " - Easy to propose multiple plausible algorithms for a problem (DnC may be more tricky. Need to decompose problem in right way)\n",
    " - Easy running time analysis bc do not need to understand recursions (DnC uses Master Method)\n",
    " - Hard to establish correctness (DnC usually have easier inductive correctness proofs); may not even have intuition for correctness\n",
    " - Most greedy algorithms are NOT correct (even if your intuition says so)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In(Correctness) Example: Dijkstra's algorithm with negative edge lengths. Will be incorrect. Easy of correctness due to myopic characteristic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Correctness Proofs:\n",
    " - Method 1: Proofs via Induction (induction on decisions made by the algorithm/# iterations)\n",
    "     - Recall Dijkstra's correctness proof\n",
    "     - \"Greedy Stays Ahead\" - prove greedy is doing right thing iteration by iteration\n",
    " - Method 2: \"Exchange Argument\" (can be by contradiction; show can take an optimal solution and exchange two elements of that optimal solution; gradually echange an optimal solution ito the one output by a greedy alogirthm without aking solution worse; more examples later)\n",
    " - Method 3: Whatever works lmfao"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimal Caching Application"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Caching Problem: \n",
    " - Has small fast memory (the cache; maybe like L2 cache)\n",
    " - Big slow memory (like main memory disk)\n",
    " - Process sequence of \"page requests\" - client wants to access something in memory, guaranteed to be in big, may be in small fast memory\n",
    "     - If not in fast memory, must bring it into there\n",
    "     - Need to evict something from cache to make room - but what? \n",
    "     \n",
    "EX: Cache with 4 slots of data, currently has [a,b,c,d].\n",
    " - Request sequence: c, d, e, f, a, b\n",
    "     - c, d (both fine, in cache), e (need to bring into cache and evict a, b, c, or d).\n",
    "     - Evict a for e; evict b for f\n",
    "     - 4 page faults (page fault is when requesnt not in cache)\n",
    "         - 2 inevitable (e and f)\n",
    "         - 2 consequences of poor eviction (should have evicted c and d instead of a and b)\n",
    "         - How to minimize faults i.e. only incur inevitable?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Optimal Caching Algorithm\n",
    "\n",
    "Theorem: (Belady 1960s) The \"furthest-in-the-future\" algorithm is optimal (i.e. minimizes the number of cache misses)\n",
    " - Want to put off \"regret\" of evicting a piece of data. When reret a piece? When it gets requested next. \n",
    " - 1 requested next, 1 requested in 7 steps, on requested in 70 steps; want to evict the one in 70 steps (furthest in future)\n",
    " - Objection: This algorithm is clairvoyant, can know the future and know when each data in cache requested next. But, this is not known in caching problem. \n",
    "     - Algorithm serves as guideline for practical algorithms\n",
    "     - LRU Algorithm (Least Recently Used Algo, look at past) - whatever used most recently may be requested again soon. Proxy for reference in future. If referenced furthest in past, may be furthest in future. Practical gold standard most times\n",
    "     - Severs as idealized benchmark for caching algorithms. Look at logs and see how caching algo performs compared to this one. \n",
    " - This algo will not be proved for correctness bc pain in the ass or smthn\n",
    " - Tricky Exchange Argument for proof. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
